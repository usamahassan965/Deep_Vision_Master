{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Self Attention in Transformers"
      ],
      "metadata": {
        "id": "gO5Z0qErNuOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Data"
      ],
      "metadata": {
        "id": "HedntyUvLrBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "L, d_k, d_v = 4, 8, 8          ### L is length of total tokens , d_k is dimension of key and d_v is dimension of value\n",
        "q = np.random.randn(L, d_k)\n",
        "k = np.random.randn(L, d_k)\n",
        "v = np.random.randn(L, d_v)"
      ],
      "metadata": {
        "id": "xtKbaWhFJui3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Q\\n\", q)\n",
        "print(\"K\\n\", k)\n",
        "print(\"V\\n\", v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09JpvuNJ2sZC",
        "outputId": "5075ce29-ad11-44d4-f496-c03a3afb4f3a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q\n",
            " [[ 1.89674261  0.16876788 -0.1147014  -1.01039339  0.22240272  1.18669652\n",
            "   1.53849536 -0.65083759]\n",
            " [ 0.75051365  0.2883125  -0.83135186 -0.42848096 -1.51048834 -0.43071518\n",
            "   0.59017915  0.25628828]\n",
            " [ 0.38115841 -0.08466821  0.02170363  0.98229443 -1.37154773 -0.32327473\n",
            "  -1.20469893  0.06098321]\n",
            " [-0.99297478  0.94789714 -1.65177143  0.88554675 -0.16072056  0.80961247\n",
            "   0.06632881 -0.06898069]]\n",
            "K\n",
            " [[ 0.4481545  -1.79396534  0.0908088  -0.74266193 -0.83537924  0.26304504\n",
            "  -1.28730123 -0.81080393]\n",
            " [-1.52075254 -0.58949283 -0.59143947 -1.07363383  1.88036975  0.62861599\n",
            "  -0.67031112 -0.12577496]\n",
            " [-0.1323446  -0.25197528 -0.41384947 -0.24159246  1.10554571 -2.77289787\n",
            "   1.96111947 -0.08857994]\n",
            " [-0.86718853  0.74922133  0.82114015 -1.39302018  0.53917891 -0.7638527\n",
            "  -0.28285176  1.4148641 ]]\n",
            "V\n",
            " [[-0.07703553 -1.56496974 -0.95833645 -0.17826546  0.07570981  0.09826632\n",
            "  -0.01383334 -1.28698563]\n",
            " [ 0.2261494  -0.64931334 -0.09503368  2.01603016  0.38349369  1.01334865\n",
            "  -0.30550586  0.78715539]\n",
            " [-1.35825696 -0.54104669 -1.33258855 -1.98936307 -0.21110388 -1.41309689\n",
            "   0.1957196  -0.8195403 ]\n",
            " [-0.02314086  1.1922242   0.3374487   0.40094203 -0.29758844 -2.58183501\n",
            "   1.33612388  1.02253491]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self Attention\n",
        "\n",
        "$$\n",
        "\\text{self attention} = softmax\\bigg(\\frac{Q.K^T}{\\sqrt{d_k}}+M\\bigg)\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{new V} = \\text{self attention}.V\n",
        "$$"
      ],
      "metadata": {
        "id": "tV6txskBLwjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.matmul(q, k.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7GePHKk3Mh0",
        "outputId": "f883cdec-0566-4d3d-a6b8-e77300d14559"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.03920645, -1.61656787,  0.02813604, -2.34763583],\n",
              "       [ 0.2428411 , -3.89844706,  0.93472338, -0.81034134],\n",
              "       [ 2.15725957, -3.57957683, -3.26326825, -1.81004684],\n",
              "       [-2.63538616,  1.14839658, -1.9242561 , -1.84008057]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Why we need sqrt(d_k) in denominator\n",
        "q.var(), k.var(), np.matmul(q, k.T).var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odK76OoI3nL2",
        "outputId": "113870fb-da3d-4c6f-da7e-12fb72318540"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(0.7485991117903039),\n",
              " np.float64(1.059126177871358),\n",
              " np.float64(3.0306764642564294))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
        "q.var(), k.var(), scaled.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ps6AY1Q3tRI",
        "outputId": "d55084b7-bf8f-415f-d9d4-df59e41c9933"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(0.7485991117903039),\n",
              " np.float64(1.059126177871358),\n",
              " np.float64(0.3788345580320537))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Notice the reduction in variance of the product. This is the reason we use square root so to stabilize the learning by reducing variance of attention matrix"
      ],
      "metadata": {
        "id": "ypO9IK1PL3cJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVHAJR4N4VQX",
        "outputId": "8e99edbe-3f96-48bb-9ebd-ec94582da368"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.01386157, -0.57154305,  0.00994759, -0.83001461],\n",
              "       [ 0.08585729, -1.37830918,  0.33047462, -0.28649893],\n",
              "       [ 0.76270644, -1.26557152, -1.15373955, -0.6399482 ],\n",
              "       [-0.93174971,  0.40601951, -0.68032727, -0.65056672]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Masking\n",
        "\n",
        "- This is to ensure words don't get context from words generated in the future.\n",
        "- Not required in the encoders, but required int he decoders"
      ],
      "metadata": {
        "id": "Dmz4v-RmMAaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask = np.tril(np.ones( (L, L) ))   ### Lower triangular matrix\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8N3OhSLILfG",
        "outputId": "c6350ecb-6994-4d4e-8410-17e81fd77c9d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0.],\n",
              "       [1., 1., 0., 0.],\n",
              "       [1., 1., 1., 0.],\n",
              "       [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask[mask == 0] = -np.inf   ### We are using -inf instead of 0 due to use of softmax ahead\n",
        "mask[mask == 1] = 0"
      ],
      "metadata": {
        "id": "hIV9K3Yn6s1V"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LK5V_T3W6vpX",
        "outputId": "bb4160a1-a011-4850-e403-9cb252572c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0., -inf, -inf, -inf],\n",
              "       [  0.,   0., -inf, -inf],\n",
              "       [  0.,   0.,   0., -inf],\n",
              "       [  0.,   0.,   0.,   0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled + mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNH1VgEf7xTa",
        "outputId": "7bdd48e5-29bb-4a5c-99ce-14e65896ca48"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.01386157,        -inf,        -inf,        -inf],\n",
              "       [ 0.08585729, -1.37830918,        -inf,        -inf],\n",
              "       [ 0.76270644, -1.26557152, -1.15373955,        -inf],\n",
              "       [-0.93174971,  0.40601951, -0.68032727, -0.65056672]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Softmax\n",
        "\n",
        "$$\n",
        "\\text{softmax} = \\frac{e^{x_i}}{\\sum_j e^x_j}\n",
        "$$"
      ],
      "metadata": {
        "id": "XMTAXjooN9eZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "  return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T"
      ],
      "metadata": {
        "id": "2R4gdRqj8W4Y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention = softmax(scaled + mask)"
      ],
      "metadata": {
        "id": "K5eg2zPy41sP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sauNmfl-1TB",
        "outputId": "94cbc0d6-65a4-4400-ec6b-ce6180ab2193"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.        , 0.        , 0.        ],\n",
              "       [0.8121691 , 0.1878309 , 0.        , 0.        ],\n",
              "       [0.78204988, 0.10288795, 0.11506216, 0.        ],\n",
              "       [0.13475123, 0.51347407, 0.17327029, 0.17850441]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_v = np.matmul(attention, v)\n",
        "new_v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAy37go56LZo",
        "outputId": "e164658d-21f8-40c8-cae8-1b83192476ea"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.07703553, -1.56496974, -0.95833645, -0.17826546,  0.07570981,\n",
              "         0.09826632, -0.01383334, -1.28698563],\n",
              "       [-0.02008803, -1.39298117, -0.79618151,  0.23389106,  0.13352113,\n",
              "         0.27014706, -0.06861845, -0.89739785],\n",
              "       [-0.19326156, -1.35294493, -0.91257525, -0.16088769,  0.07437566,\n",
              "         0.01851655, -0.01973131, -1.01979623],\n",
              "       [-0.1337351 , -0.4252172 , -0.34859627,  0.73803012,  0.11741718,\n",
              "        -0.17214688,  0.113683  ,  0.27128599]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCP2aZOU9VrT",
        "outputId": "a8f3dcde-cae9-44a8-c07b-5838ee3efb54"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.07703553, -1.56496974, -0.95833645, -0.17826546,  0.07570981,\n",
              "         0.09826632, -0.01383334, -1.28698563],\n",
              "       [ 0.2261494 , -0.64931334, -0.09503368,  2.01603016,  0.38349369,\n",
              "         1.01334865, -0.30550586,  0.78715539],\n",
              "       [-1.35825696, -0.54104669, -1.33258855, -1.98936307, -0.21110388,\n",
              "        -1.41309689,  0.1957196 , -0.8195403 ],\n",
              "       [-0.02314086,  1.1922242 ,  0.3374487 ,  0.40094203, -0.29758844,\n",
              "        -2.58183501,  1.33612388,  1.02253491]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function"
      ],
      "metadata": {
        "id": "nSiJuBQELFHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "  return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask=None):\n",
        "  d_k = q.shape[-1]\n",
        "  scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
        "  if mask is not None:\n",
        "    scaled = scaled + mask\n",
        "  attention = softmax(scaled)\n",
        "  out = np.matmul(attention, v)\n",
        "  return out, attention"
      ],
      "metadata": {
        "id": "XvTnmdcB_jdq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values, attention = scaled_dot_product_attention(q, k, v, mask=mask)\n",
        "print(\"Q\\n\", q)\n",
        "print(\"K\\n\", k)\n",
        "print(\"V\\n\", v)\n",
        "print(\"New V\\n\", values)\n",
        "print(\"Attention\\n\", attention)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSxLkZdiSLMT",
        "outputId": "a63c842a-cc5f-4c75-c111-34ff0991f793"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q\n",
            " [[ 1.89674261  0.16876788 -0.1147014  -1.01039339  0.22240272  1.18669652\n",
            "   1.53849536 -0.65083759]\n",
            " [ 0.75051365  0.2883125  -0.83135186 -0.42848096 -1.51048834 -0.43071518\n",
            "   0.59017915  0.25628828]\n",
            " [ 0.38115841 -0.08466821  0.02170363  0.98229443 -1.37154773 -0.32327473\n",
            "  -1.20469893  0.06098321]\n",
            " [-0.99297478  0.94789714 -1.65177143  0.88554675 -0.16072056  0.80961247\n",
            "   0.06632881 -0.06898069]]\n",
            "K\n",
            " [[ 0.4481545  -1.79396534  0.0908088  -0.74266193 -0.83537924  0.26304504\n",
            "  -1.28730123 -0.81080393]\n",
            " [-1.52075254 -0.58949283 -0.59143947 -1.07363383  1.88036975  0.62861599\n",
            "  -0.67031112 -0.12577496]\n",
            " [-0.1323446  -0.25197528 -0.41384947 -0.24159246  1.10554571 -2.77289787\n",
            "   1.96111947 -0.08857994]\n",
            " [-0.86718853  0.74922133  0.82114015 -1.39302018  0.53917891 -0.7638527\n",
            "  -0.28285176  1.4148641 ]]\n",
            "V\n",
            " [[-0.07703553 -1.56496974 -0.95833645 -0.17826546  0.07570981  0.09826632\n",
            "  -0.01383334 -1.28698563]\n",
            " [ 0.2261494  -0.64931334 -0.09503368  2.01603016  0.38349369  1.01334865\n",
            "  -0.30550586  0.78715539]\n",
            " [-1.35825696 -0.54104669 -1.33258855 -1.98936307 -0.21110388 -1.41309689\n",
            "   0.1957196  -0.8195403 ]\n",
            " [-0.02314086  1.1922242   0.3374487   0.40094203 -0.29758844 -2.58183501\n",
            "   1.33612388  1.02253491]]\n",
            "New V\n",
            " [[-0.07703553 -1.56496974 -0.95833645 -0.17826546  0.07570981  0.09826632\n",
            "  -0.01383334 -1.28698563]\n",
            " [-0.02008803 -1.39298117 -0.79618151  0.23389106  0.13352113  0.27014706\n",
            "  -0.06861845 -0.89739785]\n",
            " [-0.19326156 -1.35294493 -0.91257525 -0.16088769  0.07437566  0.01851655\n",
            "  -0.01973131 -1.01979623]\n",
            " [-0.1337351  -0.4252172  -0.34859627  0.73803012  0.11741718 -0.17214688\n",
            "   0.113683    0.27128599]]\n",
            "Attention\n",
            " [[1.         0.         0.         0.        ]\n",
            " [0.8121691  0.1878309  0.         0.        ]\n",
            " [0.78204988 0.10288795 0.11506216 0.        ]\n",
            " [0.13475123 0.51347407 0.17327029 0.17850441]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-HtQQtB2LJus"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
