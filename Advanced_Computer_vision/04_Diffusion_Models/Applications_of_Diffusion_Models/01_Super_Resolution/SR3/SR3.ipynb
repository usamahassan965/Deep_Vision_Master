{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install lmdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tc6SkmMTt8_s",
        "outputId": "daada36e-4bc7-4952-a198-b554ce110035"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lmdb\n",
            "  Downloading lmdb-1.7.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\n",
            "Downloading lmdb-1.7.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (299 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/299.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.4/299.4 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lmdb\n",
            "Successfully installed lmdb-1.7.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFO7DMo0bNhm"
      },
      "source": [
        "# **Image Super-Resolution**\n",
        "**64x64 -> 512x512**\n",
        "\n",
        "A colab notebook for upscaling 64x64 images to 512x512, using [this](https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YpW_YQQaa8U"
      },
      "source": [
        "## Setup\n",
        "---\n",
        "Instructions:\n",
        "\n",
        "*   Turn on hardware acceleration under `Runtime -> Change Runtime Type -> Hardware accelerator -> GPU`\n",
        "*   Use this command to ensure that the connected machine has a GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWHYjb8WanA3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b72e926-05bd-4ca3-c14c-55ff65c30f28"
      },
      "source": [
        "!nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name, driver_version, memory.total [MiB]\n",
            "Tesla T4, 550.54.15, 15360 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcKEMsB4b3IB"
      },
      "source": [
        "*    Now, execute each cell sequentially, waiting until each one is done before running the next cell.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxwQpOG8cXHx"
      },
      "source": [
        "### Clone repo, download a pre-trained model, install dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wZutZK1hPJp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6959f67b-f48d-4467-d37f-f769bd7d1aa4"
      },
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement.git\n",
        "!pip install tensorboardx"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'Image-Super-Resolution-via-Iterative-Refinement'...\n",
            "remote: Enumerating objects: 569, done.\u001b[K\n",
            "remote: Counting objects: 100% (315/315), done.\u001b[K\n",
            "remote: Compressing objects: 100% (96/96), done.\u001b[K\n",
            "remote: Total 569 (delta 251), reused 219 (delta 219), pack-reused 254 (from 2)\u001b[K\n",
            "Receiving objects: 100% (569/569), 10.00 MiB | 14.68 MiB/s, done.\n",
            "Resolving deltas: 100% (299/299), done.\n",
            "Collecting tensorboardx\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from tensorboardx) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboardx) (25.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.12/dist-packages (from tensorboardx) (5.29.5)\n",
            "Downloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardx\n",
            "Successfully installed tensorboardx-2.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now for the download of the pre-trained model file.\n",
        "\n",
        "Go to the [trained model location](https://drive.google.com/drive/folders/1mCiWhFqHyjt5zE4IdA41fjFwCYdqDzSF) in Google Drive, then right click on the first file and select \"Add a shortcut to Drive\". Then, choose whichever location to put it in your own Google Drive."
      ],
      "metadata": {
        "id": "X7uSOFgZwNo8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can now connect this Colab section to your Drive to retrieve the file."
      ],
      "metadata": {
        "id": "K2IWrOFXytat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "DyZzm-eIW29X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2383f386-b584-43e9-c4ba-1cebdcc9cf96"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change the path if you put it elsewhere"
      ],
      "metadata": {
        "id": "IVjxeipFykxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_location = '/content/drive/MyDrive'"
      ],
      "metadata": {
        "id": "bxjaJKn_wM11"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute to copy from the Drive to the Colab session"
      ],
      "metadata": {
        "id": "Y785Y0H3y8Ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp {file_location}/I830000_E32_gen.pth /content/Image-Super-Resolution-via-Iterative-Refinement/"
      ],
      "metadata": {
        "id": "MduofkA4YzeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef8aea1a-b192-4840-ee2a-00f5cbf2afe7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/drive/MyDrive/I830000_E32_gen.pth': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fx9_SzGrcvqt"
      },
      "source": [
        "### Patch config files\n",
        "\n",
        "Create patchfile\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_Sv8UJu0d5i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8170358-fef1-406a-9d37-94025ca2977d"
      },
      "source": [
        "%%writefile 64_512.patch\n",
        "--- sr_sr3_64_512_new.json\t2021-10-22 16:20:20.901133618 +0000\n",
        "+++ sr_sr3_64_512.json\t2021-10-22 16:20:52.036081672 +0000\n",
        "@@ -9,8 +9,8 @@\n",
        "         \"tb_logger\": \"tb_logger\",\n",
        "         \"results\": \"results\",\n",
        "         \"checkpoint\": \"checkpoint\",\n",
        "-        \"resume_state\": null\n",
        "-        // \"resume_state\": \"experiments/distributed_high_sr_ffhq_210901_121212/checkpoint/I830000_E32\" //pretrain model or training state\n",
        "+        // \"resume_state\": null\n",
        "+        \"resume_state\": \"I830000_E32\" //pretrain model or training state\n",
        "     },\n",
        "     \"datasets\": {\n",
        "         \"train\": {\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing 64_512.patch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix9vWlDmc8zu"
      },
      "source": [
        "Apply patchfile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvA6tCTk5N8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b872ae62-136a-461a-8352-0c5646095f18"
      },
      "source": [
        "!apt-get install dos2unix\n",
        "!dos2unix sr_sr3_64_512.json\n",
        "!patch < 64_512.patch"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  dos2unix\n",
            "0 upgraded, 1 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 384 kB of archives.\n",
            "After this operation, 1,367 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 dos2unix amd64 7.4.2-2 [384 kB]\n",
            "Fetched 384 kB in 2s (243 kB/s)\n",
            "Selecting previously unselected package dos2unix.\n",
            "(Reading database ... 121689 files and directories currently installed.)\n",
            "Preparing to unpack .../dos2unix_7.4.2-2_amd64.deb ...\n",
            "Unpacking dos2unix (7.4.2-2) ...\n",
            "Setting up dos2unix (7.4.2-2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "dos2unix: sr_sr3_64_512.json: No such file or directory\n",
            "dos2unix: Skipping sr_sr3_64_512.json, not a regular file.\n",
            "can't find file to patch at input line 3\n",
            "Perhaps you should have used the -p or --strip option?\n",
            "The text leading up to this was:\n",
            "--------------------------\n",
            "|--- sr_sr3_64_512_new.json\t2021-10-22 16:20:20.901133618 +0000\n",
            "|+++ sr_sr3_64_512.json\t2021-10-22 16:20:52.036081672 +0000\n",
            "--------------------------\n",
            "File to patch: \n",
            "Skip this patch? [y] \n",
            "Skipping patch.\n",
            "1 out of 1 hunk ignored\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYpuGLzAdSi6"
      },
      "source": [
        "### Prepare Data\n",
        "Upload 64x64 pixel image(s) to be upscaled\n",
        "\n",
        "*Click the **browse** button and select the images you would like to upscale.*\n",
        "\n",
        "Note that the image does not need to be 64x64 since it will be resized in a pre-processing step, however it is better to upload a square image in order to avoid a distorsion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waO5ob8n-EWE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "44c06250-9a0a-4cf0-ef2f-089a689c8f5b"
      },
      "source": [
        "%cd /content/Image-Super-Resolution-via-Iterative-Refinement/\n",
        "!mkdir -p input\n",
        "%cd /content/Image-Super-Resolution-via-Iterative-Refinement/input/\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  savefile = open(fn, 'wb')\n",
        "  savefile.write(uploaded[fn])\n",
        "  print('Successfully uploaded \"{}\" ({} bytes).'.format(fn, len(uploaded[fn])))\n",
        "  savefile.close()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Image-Super-Resolution-via-Iterative-Refinement\n",
            "/content/Image-Super-Resolution-via-Iterative-Refinement/input\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2fa2bc0c-8526-42ac-b82a-83591d182764\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2fa2bc0c-8526-42ac-b82a-83591d182764\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Profile.jpg to Profile.jpg\n",
            "Successfully uploaded \"Profile.jpg\" (59697 bytes).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEOiBK5ldm1M"
      },
      "source": [
        "Generate neccesary files and directory structure to begin upscaling.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GNfEu9gsseU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5493763-8057-4172-ca62-c353f8264bee"
      },
      "source": [
        "%cd /content/Image-Super-Resolution-via-Iterative-Refinement/\n",
        "!python data/prepare_data.py --path /content/Image-Super-Resolution-via-Iterative-Refinement/input/ --size 64,512 --out ./dataset/celebahq"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Image-Super-Resolution-via-Iterative-Refinement\n",
            "0/1 images processed "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsF6C2sgeuyq"
      },
      "source": [
        "## Upscaling\n",
        "---\n",
        "Note that this may take ~30 minutes or more, depending on which GPU you get.\n",
        "\n",
        "Output images will be located under ./experiments/\\<some folder\\>/results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing wandb on the Colab machine (by default it is not installed)"
      ],
      "metadata": {
        "id": "5gpVxMdCwE2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "vreCwLbGVyo7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aeb8f8f-f968-4969-af25-9b4c3831f1db"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.23.1)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.12.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.47.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUS4C0ZYc578",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bdcdeeb-9161-43a4-e87b-cf3102908e17"
      },
      "source": [
        "!python infer.py -c /content/Image-Super-Resolution-via-Iterative-Refinement/config/sr_sr3_64_512.json"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "export CUDA_VISIBLE_DEVICES=0,1\n",
            "26-01-05 19:53:31.599 - INFO:   name: distributed_high_sr_ffhq\n",
            "  phase: val\n",
            "  gpu_ids: [0, 1]\n",
            "  path:[\n",
            "    log: experiments/distributed_high_sr_ffhq_260105_195331/logs\n",
            "    tb_logger: experiments/distributed_high_sr_ffhq_260105_195331/tb_logger\n",
            "    results: experiments/distributed_high_sr_ffhq_260105_195331/results\n",
            "    checkpoint: experiments/distributed_high_sr_ffhq_260105_195331/checkpoint\n",
            "    resume_state: None\n",
            "    experiments_root: experiments/distributed_high_sr_ffhq_260105_195331\n",
            "  ]\n",
            "  datasets:[\n",
            "    train:[\n",
            "      name: FFHQ\n",
            "      mode: HR\n",
            "      dataroot: dataset/ffhq_64_512\n",
            "      datatype: img\n",
            "      l_resolution: 64\n",
            "      r_resolution: 512\n",
            "      batch_size: 2\n",
            "      num_workers: 8\n",
            "      use_shuffle: True\n",
            "      data_len: -1\n",
            "    ]\n",
            "    val:[\n",
            "      name: CelebaHQ\n",
            "      mode: LRHR\n",
            "      dataroot: dataset/celebahq_64_512\n",
            "      datatype: img\n",
            "      l_resolution: 64\n",
            "      r_resolution: 512\n",
            "      data_len: 50\n",
            "    ]\n",
            "  ]\n",
            "  model:[\n",
            "    which_model_G: sr3\n",
            "    finetune_norm: False\n",
            "    unet:[\n",
            "      in_channel: 6\n",
            "      out_channel: 3\n",
            "      inner_channel: 64\n",
            "      norm_groups: 16\n",
            "      channel_multiplier: [1, 2, 4, 8, 16]\n",
            "      attn_res: []\n",
            "      res_blocks: 1\n",
            "      dropout: 0\n",
            "    ]\n",
            "    beta_schedule:[\n",
            "      train:[\n",
            "        schedule: linear\n",
            "        n_timestep: 2000\n",
            "        linear_start: 1e-06\n",
            "        linear_end: 0.01\n",
            "      ]\n",
            "      val:[\n",
            "        schedule: linear\n",
            "        n_timestep: 2000\n",
            "        linear_start: 1e-06\n",
            "        linear_end: 0.01\n",
            "      ]\n",
            "    ]\n",
            "    diffusion:[\n",
            "      image_size: 512\n",
            "      channels: 3\n",
            "      conditional: True\n",
            "    ]\n",
            "  ]\n",
            "  train:[\n",
            "    n_iter: 1000000\n",
            "    val_freq: 10000.0\n",
            "    save_checkpoint_freq: 10000.0\n",
            "    print_freq: 50\n",
            "    optimizer:[\n",
            "      type: adam\n",
            "      lr: 3e-06\n",
            "    ]\n",
            "    ema_scheduler:[\n",
            "      step_start_ema: 5000\n",
            "      update_ema_every: 1\n",
            "      ema_decay: 0.9999\n",
            "    ]\n",
            "  ]\n",
            "  wandb:[\n",
            "    project: distributed_high_sr_ffhq\n",
            "  ]\n",
            "  distributed: True\n",
            "  log_infer: False\n",
            "  enable_wandb: False\n",
            "\n",
            "26-01-05 19:53:31.604 - INFO: Dataset [LRHRDataset - CelebaHQ] is created.\n",
            "26-01-05 19:53:31.604 - INFO: Initial Dataset Finished\n",
            "26-01-05 19:53:33.072 - INFO: Network G structure: DataParallel - GaussianDiffusion, with parameters: 155,334,339\n",
            "26-01-05 19:53:33.072 - INFO: GaussianDiffusion(\n",
            "  (denoise_fn): UNet(\n",
            "    (noise_level_mlp): Sequential(\n",
            "      (0): PositionalEncoding()\n",
            "      (1): Linear(in_features=64, out_features=256, bias=True)\n",
            "      (2): Swish()\n",
            "      (3): Linear(in_features=256, out_features=64, bias=True)\n",
            "    )\n",
            "    (downs): ModuleList(\n",
            "      (0): Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ResnetBlocWithAttn(\n",
            "        (res_block): ResnetBlock(\n",
            "          (noise_func): FeatureWiseAffine(\n",
            "            (noise_func): Sequential(\n",
            "              (0): Linear(in_features=64, out_features=64, bias=True)\n",
            "            )\n",
            "          )\n",
            "          (block1): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (block2): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (res_conv): Identity()\n",
            "        )\n",
            "      )\n",
            "      (2): Downsample(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      )\n",
            "      (3): ResnetBlocWithAttn(\n",
            "        (res_block): ResnetBlock(\n",
            "          (noise_func): FeatureWiseAffine(\n",
            "            (noise_func): Sequential(\n",
            "              (0): Linear(in_features=64, out_features=128, bias=True)\n",
            "            )\n",
            "          )\n",
            "          (block1): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (block2): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (res_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (4): Downsample(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      )\n",
            "      (5): ResnetBlocWithAttn(\n",
            "        (res_block): ResnetBlock(\n",
            "          (noise_func): FeatureWiseAffine(\n",
            "            (noise_func): Sequential(\n",
            "              (0): Linear(in_features=64, out_features=256, bias=True)\n",
            "            )\n",
            "          )\n",
            "          (block1): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (block2): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (res_conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (6): Downsample(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      )\n",
            "      (7): ResnetBlocWithAttn(\n",
            "        (res_block): ResnetBlock(\n",
            "          (noise_func): FeatureWiseAffine(\n",
            "            (noise_func): Sequential(\n",
            "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
            "            )\n",
            "          )\n",
            "          (block1): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (block2): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (res_conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (8): Downsample(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      )\n",
            "      (9): ResnetBlocWithAttn(\n",
            "        (res_block): ResnetBlock(\n",
            "          (noise_func): FeatureWiseAffine(\n",
            "            (noise_func): Sequential(\n",
            "              (0): Linear(in_features=64, out_features=1024, bias=True)\n",
            "            )\n",
            "          )\n",
            "          (block1): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (block2): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (res_conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (mid): ModuleList(\n",
            "      (0): ResnetBlocWithAttn(\n",
            "        (res_block): ResnetBlock(\n",
            "          (noise_func): FeatureWiseAffine(\n",
            "            (noise_func): Sequential(\n",
            "              (0): Linear(in_features=64, out_features=1024, bias=True)\n",
            "            )\n",
            "          )\n",
            "          (block1): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (block2): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (res_conv): Identity()\n",
            "        )\n",
            "        (attn): SelfAttention(\n",
            "          (norm): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
            "          (qkv): Conv2d(1024, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (out): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (1): ResnetBlocWithAttn(\n",
            "        (res_block): ResnetBlock(\n",
            "          (noise_func): FeatureWiseAffine(\n",
            "            (noise_func): Sequential(\n",
            "              (0): Linear(in_features=64, out_features=1024, bias=True)\n",
            "            )\n",
            "          )\n",
            "          (block1): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (block2): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (res_conv): Identity()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ups): ModuleList(\n",
            "      (0): ResnetBlocWithAttn(\n",
            "        (res_block): ResnetBlock(\n",
            "          (noise_func): FeatureWiseAffine(\n",
            "            (noise_func): Sequential(\n",
            "              (0): Linear(in_features=64, out_features=1024, bias=True)\n",
            "            )\n",
            "          )\n",
            "          (block1): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 2048, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (block2): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (res_conv): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (1): ResnetBlocWithAttn(\n",
            "        (res_block): ResnetBlock(\n",
            "          (noise_func): FeatureWiseAffine(\n",
            "            (noise_func): Sequential(\n",
            "              (0): Linear(in_features=64, out_features=1024, bias=True)\n",
            "            )\n",
            "          )\n",
            "          (block1): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 1536, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(1536, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (block2): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (res_conv): Conv2d(1536, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (2): Upsample(\n",
            "        (up): Upsample(scale_factor=2.0, mode='nearest')\n",
            "        (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "      (3): ResnetBlocWithAttn(\n",
            "        (res_block): ResnetBlock(\n",
            "          (noise_func): FeatureWiseAffine(\n",
            "            (noise_func): Sequential(\n",
            "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
            "            )\n",
            "          )\n",
            "          (block1): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 1536, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (block2): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (res_conv): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (4): ResnetBlocWithAttn(\n",
            "        (res_block): ResnetBlock(\n",
            "          (noise_func): FeatureWiseAffine(\n",
            "            (noise_func): Sequential(\n",
            "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
            "            )\n",
            "          )\n",
            "          (block1): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 768, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (block2): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (res_conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (5): Upsample(\n",
            "        (up): Upsample(scale_factor=2.0, mode='nearest')\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "      (6): ResnetBlocWithAttn(\n",
            "        (res_block): ResnetBlock(\n",
            "          (noise_func): FeatureWiseAffine(\n",
            "            (noise_func): Sequential(\n",
            "              (0): Linear(in_features=64, out_features=256, bias=True)\n",
            "            )\n",
            "          )\n",
            "          (block1): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 768, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (block2): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (res_conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (7): ResnetBlocWithAttn(\n",
            "        (res_block): ResnetBlock(\n",
            "          (noise_func): FeatureWiseAffine(\n",
            "            (noise_func): Sequential(\n",
            "              (0): Linear(in_features=64, out_features=256, bias=True)\n",
            "            )\n",
            "          )\n",
            "          (block1): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 384, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (block2): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (8): Upsample(\n",
            "        (up): Upsample(scale_factor=2.0, mode='nearest')\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "      (9): ResnetBlocWithAttn(\n",
            "        (res_block): ResnetBlock(\n",
            "          (noise_func): FeatureWiseAffine(\n",
            "            (noise_func): Sequential(\n",
            "              (0): Linear(in_features=64, out_features=128, bias=True)\n",
            "            )\n",
            "          )\n",
            "          (block1): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 384, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (block2): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (res_conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (10): ResnetBlocWithAttn(\n",
            "        (res_block): ResnetBlock(\n",
            "          (noise_func): FeatureWiseAffine(\n",
            "            (noise_func): Sequential(\n",
            "              (0): Linear(in_features=64, out_features=128, bias=True)\n",
            "            )\n",
            "          )\n",
            "          (block1): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 192, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (block2): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (11): Upsample(\n",
            "        (up): Upsample(scale_factor=2.0, mode='nearest')\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "      (12): ResnetBlocWithAttn(\n",
            "        (res_block): ResnetBlock(\n",
            "          (noise_func): FeatureWiseAffine(\n",
            "            (noise_func): Sequential(\n",
            "              (0): Linear(in_features=64, out_features=64, bias=True)\n",
            "            )\n",
            "          )\n",
            "          (block1): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 192, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (block2): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (res_conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (13): ResnetBlocWithAttn(\n",
            "        (res_block): ResnetBlock(\n",
            "          (noise_func): FeatureWiseAffine(\n",
            "            (noise_func): Sequential(\n",
            "              (0): Linear(in_features=64, out_features=64, bias=True)\n",
            "            )\n",
            "          )\n",
            "          (block1): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (block2): Block(\n",
            "            (block): Sequential(\n",
            "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
            "              (1): Swish()\n",
            "              (2): Identity()\n",
            "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (res_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (final_conv): Block(\n",
            "      (block): Sequential(\n",
            "        (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
            "        (1): Swish()\n",
            "        (2): Identity()\n",
            "        (3): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (loss_func): L1Loss()\n",
            ")\n",
            "26-01-05 19:53:33.130 - INFO: Model [DDPM] is created.\n",
            "26-01-05 19:53:33.130 - INFO: Initial Model Finished\n",
            "26-01-05 19:53:33.131 - INFO: Begin Model Inference.\n",
            "sampling loop time step: 100% 2000/2000 [10:01<00:00,  3.32it/s]\n",
            "sampling loop time step: 100% 2000/2000 [09:55<00:00,  3.36it/s]\n",
            "sampling loop time step: 100% 2000/2000 [09:56<00:00,  3.36it/s]\n",
            "sampling loop time step: 100% 2000/2000 [09:55<00:00,  3.36it/s]\n",
            "sampling loop time step: 100% 2000/2000 [09:55<00:00,  3.36it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now visualize the results !"
      ],
      "metadata": {
        "id": "pUoKqjJf-6JV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "\n",
        "original = plt.imread('input/Poutine6cropped.jpg')\n",
        "downsized = plt.imread('experiments/distributed_high_sr_ffhq_220301_125109/results/0_5_inf.png')\n",
        "infered = plt.imread('experiments/distributed_high_sr_ffhq_220301_125109/results/0_5_hr.png')\n",
        "\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.subplot(131)\n",
        "plt.imshow(original)\n",
        "plt.title('Original high resolution image')\n",
        "plt.subplot(132)\n",
        "plt.imshow(downsized)\n",
        "plt.title('Resized low resolution image')\n",
        "plt.subplot(133)\n",
        "plt.imshow(infered)\n",
        "plt.title('High resolution image infered from the low resolution one')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k2DCzczpzqoR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "9e0eb310-437b-4fe1-a1c2-25ce6fdb293d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'input/Poutine6cropped.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3452224363.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input/Poutine6cropped.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdownsized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'experiments/distributed_high_sr_ffhq_220301_125109/results/0_5_inf.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0minfered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'experiments/distributed_high_sr_ffhq_220301_125109/results/0_5_hr.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2611\u001b[0m         \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mBinaryIO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2612\u001b[0m ) -> np.ndarray:\n\u001b[0;32m-> 2613\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1500\u001b[0m             \u001b[0;34m\"``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m             )\n\u001b[0;32m-> 1502\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mimg_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1503\u001b[0m         return (_pil_png_to_float_array(image)\n\u001b[1;32m   1504\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPngImagePlugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPngImageFile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3513\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3514\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3515\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input/Poutine6cropped.jpg'"
          ]
        }
      ]
    }
  ]
}